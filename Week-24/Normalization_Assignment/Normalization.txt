Question 1: Normalization
Consider the following unnormalized table for a bookstore database:
| Book ID | Title                   | Author              | Genre   | Publisher      | ISBN           | Price |
|---------|-------------------------|---------------------|---------|-----------------|-----------------|-------|
| 101     | To Kill a Mockingbird   | Harper Lee          | Fiction | HarperCollins   | 978-0061120084 | 10.99 |
| 102     | The Great Gatsby        | F. Scott Fitzgerald | Fiction | Scribner        | 978-0743273565 | 12.50 |
| 103     | Principles of Physics   | Jearl Walker        | Science | Wiley           | 978-0321976444 | 50.00 |

Normalize the table to 1NF, 2NF, and 3NF, explaining the steps you took at each normalization level.

Answer => 
1NF (First Normal Form):
In 1NF, each cell of the table should contain atomic (indivisible) values. The given table already satisfies 1NF because each cell contains a single value.

2NF (Second Normal Form):
To achieve 2NF, we need to make sure that every non-prime attribute is fully functionally dependent on the primary key. In this case, let's assume that `Book ID` is the primary key. All attributes are fully dependent on the entire primary key, so the table is already in 2NF.

3NF (Third Normal Form):
In 3NF, we address transitive dependencies. The only transitive dependency here is the `Publisher` on the `Book ID` since it depends on the `Book ID` but not on the primary key (`ISBN`). To eliminate this, we create a new table for `Publishers`.

Table 1: Books
| Book ID | Title                   | Author              | Genre   | ISBN           | Price |
|---------|-------------------------|---------------------|---------|-----------------|-------|
| 101     | To Kill a Mockingbird   | Harper Lee          | Fiction | 978-0061120084 | 10.99 |
| 102     | The Great Gatsby        | F. Scott Fitzgerald | Fiction | 978-0743273565 | 12.50 |
| 103     | Principles of Physics   | Jearl Walker        | Science | 978-0321976444 | 50.00 |

Table 2: Publishers
| Book ID | Publisher       |
|---------|-----------------|
| 101     | HarperCollins   |
| 102     | Scribner         |
| 103     | Wiley            |

Now, the tables are in 3NF. The `Publishers` table has a foreign key (`Book ID`) linking it to the `Books` table, and all transitive dependencies have been eliminated.


Qyestion 2: Apply Normalization on the below table and return the list of tables after 1NF, 2NF, 3NF, 4NF, 5NF( if applicable)

Table: Employee Information
| Employee ID | Employee Name | Department | Project ID | Project Name | Start Date  | End Date    | Salary |
|-------------|---------------|------------|------------|--------------|-------------|-------------|--------|
| 101         | John Doe      | HR         | 001        | Project A    | 2023-01-15  | 2023-06-30  | 5000   |
| 101         | John Doe      | HR         | 002        | Project B    | 2023-04-01  | 2023-08-31  | 5200   |
| 102         | Jane Smith    | Marketing  | 001        | Project A    | 2023-02-01  | 2023-05-31  | 5500   |
| 103         | Mike Johnson  | IT         | 002        | Project B    | 2023-03-10  | 2023-08-15  | 6000   |
| 103         | Mike Johnson  | IT         | 003        | Project C    | 2023-06-15  | 2023-11-30  | 6200   |
| 104         | Sarah Brown   | HR         | 002        | Project B    | 2023-04-20  | 2023-07-31  | 4800   |
| 105         | Robert Lee    | Finance    | 001        | Project A    | 2023-05-05  | 2023-09-30  | 5200   |
| 106         | Lisa Wang     | IT         | 001        | Project A    | 2023-06-01  | 2023-12-31  | 5800   |


Answer => 
1NF (First Normal Form):
In 1NF, each cell of the table should contain atomic (indivisible) values. Looking at the table, it appears to be in 1NF because each cell contains a single value.

2NF (Second Normal Form):
To achieve 2NF, we need to make sure that every non-prime attribute is fully functionally dependent on the primary key. In this case, let's assume that the combination of `Employee ID` and `Project ID` can be considered as the composite primary key. However, we have a partial dependency on `Employee ID` since `Salary` depends only on `Employee ID`, not on the entire composite key. Therefore, we need to create a new table for employee details.

Table 1: Employees
| Employee ID | Employee Name | Department |
|-------------|---------------|------------|
| 101         | John Doe      | HR         |
| 102         | Jane Smith    | Marketing  |
| 103         | Mike Johnson  | IT         |
| 104         | Sarah Brown   | HR         |
| 105         | Robert Lee    | Finance    |
| 106         | Lisa Wang     | IT         |

Table 2: Employee_Projects
| Employee ID | Project ID | Start Date  | End Date    | Salary |
|-------------|------------|-------------|-------------|--------|
| 101         | 001        | 2023-01-15  | 2023-06-30  | 5000   |
| 101         | 002        | 2023-04-01  | 2023-08-31  | 5200   |
| 102         | 001        | 2023-02-01  | 2023-05-31  | 5500   |
| 103         | 002        | 2023-03-10  | 2023-08-15  | 6000   |
| 103         | 003        | 2023-06-15  | 2023-11-30  | 6200   |
| 104         | 002        | 2023-04-20  | 2023-07-31  | 4800   |
| 105         | 001        | 2023-05-05  | 2023-09-30  | 5200   |
| 106         | 001        | 2023-06-01  | 2023-12-31  | 5800   |

Now, the tables are in 2NF.

3NF (Third Normal Form):
In 3NF, we need to eliminate transitive dependencies. The only transitive dependency in this case is `Department` on `Employee ID` in the `Employees` table. Therefore, we create a new table for departments.

Table 3: Departments
| Department | Supervisor   |
|------------|--------------|
| HR         | John Doe     |
| Marketing  | Jane Smith   |
| IT         | Mike Johnson |
| Finance    | Robert Lee   |

Now, the tables are in 3NF.

4NF (Fourth Normal Form):
In 4NF, we address multi-valued dependencies. There are no evident multi-valued dependencies in this example, so the tables remain in 3NF.

5NF (Fifth Normal Form):
In 5NF, we deal with cases where there are join dependencies. In this example, there are no apparent join dependencies requiring further normalization.

To summarize, the tables in 1NF, 2NF, 3NF, 4NF, and 5NF (if applicable) are:

1. Employees
2. Employee_Projects
3. Departments


Question 3: What are the primary keys and foreign keys in a relational database, and how do they establish relationships between tables?

Answer =>
In a relational database, primary keys and foreign keys are crucial concepts that help establish relationships between tables. These keys enforce data integrity and enable the database to maintain consistency and coherence in the relationships between different tables.

Primary Key:
- Definition: A primary key is a unique identifier for a record in a table. It ensures that each row in a table is uniquely identified and that no two rows have the same primary key value.
- Properties:
  - Uniqueness: Each value in the primary key column must be unique.
  - Non-null: A primary key column cannot have a NULL value.
  - Fixed: Primary key values should not change over time.
- Example: In a table of employees, an `Employee ID` column can be a primary key.

Foreign Key:
- Definition: A foreign key is a column or set of columns in a table that refers to the primary key in another table. It establishes a link between the two tables, representing a relationship between them.
- Properties:
  - Values must match a primary key or unique constraint in another table.
  - Can have NULL values, indicating that the relationship is optional.
- Example: In a table of orders, a `Customer ID` column can be a foreign key that refers to the `Customer ID` column in a separate `Customers` table.

Establishing Relationships between Tables:
1. One-to-One Relationship:
   - In a one-to-one relationship, each record in the first table corresponds to exactly one record in the second table, and vice versa.
   - Example: A table of employees with a primary key `Employee ID` could have a related table of employee contact information with a foreign key `Employee ID`.

2. One-to-Many Relationship:
   - In a one-to-many relationship, each record in the first table can be related to multiple records in the second table, but each record in the second table corresponds to only one record in the first table.
   - Example: A table of customers with a primary key `Customer ID` could be related to a table of orders with a foreign key `Customer ID`.

3. Many-to-Many Relationship:
   - In a many-to-many relationship, each record in the first table can be related to multiple records in the second table, and vice versa.
   - To represent a many-to-many relationship, an intermediate table (junction table or associative table) is created, and both primary keys from the related tables become foreign keys in the intermediate table.
   - Example: A table of students and a table of courses could have an intermediate table to represent the enrollment relationship, with foreign keys `Student ID` and `Course ID`.

By using primary and foreign keys, relational databases can establish and maintain these relationships, ensuring data integrity and supporting efficient data retrieval and manipulation operations.



Question 4: Explain the ACID properties in the context of database transactions.

Answer => 
The ACID properties are a set of characteristics that guarantee the reliability and consistency of database transactions. These properties ensure that database transactions are executed in a way that preserves the integrity of the data, even in the face of errors, failures, or system crashes. ACID stands for Atomicity, Consistency, Isolation, and Durability.

1. Atomicity:
   - Definition: Atomicity ensures that a transaction is treated as a single, indivisible unit of work. Either all the changes made by the transaction are committed to the database, or none of them are.
   - Example: Consider a bank transfer where money is withdrawn from one account and deposited into another. Atomicity ensures that both operations either succeed together (commit) or fail together (rollback), maintaining the integrity of the accounts.

2. Consistency:
   - Definition: Consistency ensures that a transaction brings the database from one valid state to another. It enforces integrity constraints, domain constraints, and other rules defined for the database.
   - Example: If an operation violates a constraint (e.g., a unique key constraint), the entire transaction is rolled back to maintain a consistent state, preventing the database from being in an invalid or inconsistent state.

3. Isolation:
   - Definition: Isolation ensures that the execution of one transaction is isolated from the execution of other transactions. Each transaction appears to run in isolation, without interference from other concurrent transactions.
   - Example: If two transactions are executing concurrently, their intermediate states should not be visible to each other. Isolation prevents issues like dirty reads, non-repeatable reads, and phantom reads.

4. Durability:
   - Definition: Durability guarantees that once a transaction is committed, its changes are permanent and will survive any subsequent failures, such as system crashes or power outages.
   - Example: After a user receives a confirmation that a transaction is successful (e.g., funds transfer), the changes made by the transaction are stored in a durable storage medium (disk). Even if the system crashes afterward, the changes will be recovered upon system restart.

Together, these ACID properties provide a framework for building robust and reliable database systems, ensuring that transactions maintain the integrity of the data and can be trusted even in the face of unexpected events. ACID compliance is critical for applications where data consistency and reliability are paramount, such as financial systems, healthcare databases, and other mission-critical applications.


Question 5: Describe the concept of indexing in a database. How does indexing improve query performance?

Answer =>
Indexing is a database optimization technique used to improve the speed and efficiency of data retrieval operations, particularly queries. An index is a data structure that provides a quick lookup or reference to the actual data rows in a table based on the values in one or more columns. By creating indexes on specific columns, databases can significantly enhance query performance, especially for SELECT operations.

Key Concepts of Indexing:

1. Index Structure:
   - An index consists of a set of key-value pairs, where the key is the indexed column(s) and the value is a pointer or reference to the actual data in the table.
   - Indexes are typically stored separately from the actual data, maintaining a sorted or hashed structure for quick search operations.

2. Types of Indexes:
   - Single-column Index: Created on a single column.
   - Composite Index: Created on multiple columns.
   - Unique Index: Ensures that values in the indexed columns are unique.
   - Clustered Index: Determines the physical order of rows in the table.
   - Non-clustered Index: Creates a separate structure for indexing without affecting the physical order of rows.

How Indexing Improves Query Performance:

1. Faster Data Retrieval:
   - When a query involves conditions specified in the WHERE clause, the database can use indexes to quickly locate the relevant rows instead of scanning the entire table. This significantly reduces the number of I/O operations.

2. Ordering and Sorting:
   - Indexes help in maintaining the sorted order of data, making operations like ORDER BY more efficient. The database engine can utilize the index to avoid sorting the entire result set.

3. Enhanced Join Performance:
   - When joining multiple tables, indexes on the join columns can speed up the process. Indexes allow the database engine to quickly match corresponding rows between tables.

4. Aggregation and Grouping:
   - Indexes can also improve the performance of operations involving aggregation functions (SUM, AVG, COUNT) and GROUP BY clauses. The database can use indexes to locate and process the necessary data more efficiently.

5. Covering Index:
   - A covering index is an index that includes all the columns required by a query, eliminating the need for the database engine to access the actual data pages. This can further enhance performance by reducing I/O operations.

6. Query Optimization:
   - The database query optimizer uses indexes to choose the most efficient execution plan. It evaluates different access paths and joins to determine the best way to retrieve the data.

Considerations and Trade-offs:

1. Overhead during Write Operations:
   - While indexing improves query performance, it can introduce overhead during insert, update, and delete operations. Each modification to indexed columns may require corresponding updates to the index structure.

2. Disk Space Usage:
   - Indexes consume additional disk space. Care should be taken to balance the benefits of improved query performance against the increased storage requirements.

3. Selectivity:
   - The selectivity of an index is crucial. A highly selective index is more effective because it narrows down the search space, whereas a low selectivity index may not provide significant performance improvements.

In summary, indexing plays a vital role in enhancing database performance by facilitating faster data retrieval, optimizing query execution plans, and improving the efficiency of various database operations. However, it requires careful consideration and maintenance to ensure a balance between query performance and the impact on write operations and disk space.


Question 6: Explain the concept of concurrency control, deadlocks in a multi-user database environment.

Answer =>
Concurrency control is a critical aspect of managing simultaneous access to a database by multiple users or transactions. In a multi-user database environment, multiple transactions may be executing concurrently, and concurrency control mechanisms are employed to ensure data consistency and avoid conflicts that may arise when multiple transactions try to access or modify the same data simultaneously.

Goals of Concurrency Control:
1. Isolation: Transactions should execute as if they are the only transactions in the system, ensuring that their intermediate states are not visible to other transactions until they are committed.
2. Consistency: Concurrent execution should not compromise the consistency of the database. The final state of the database should be consistent with the execution of each individual transaction.
3. Serializability: The result of executing concurrent transactions should be equivalent to some serial order of execution, ensuring that the final state is as if the transactions were executed one after the other.

Concurrency Control Mechanisms:
1. Locking:
   - Transactions acquire locks on data items to control access. There are different types of locks, such as shared locks (read) and exclusive locks (write).
   - A transaction must request and acquire a lock before reading or modifying a data item. Locks prevent other transactions from accessing the same data simultaneously.

2. Timestamp Ordering:
   - Transactions are assigned unique timestamps, and the order of their execution is determined by these timestamps.
   - Conflicts are resolved based on the timestamps, ensuring a consistent and serializable order of execution.

3. Multiversion Concurrency Control (MVCC):
   - Maintains multiple versions of each data item to allow transactions to read a consistent snapshot of the database.
   - Each transaction sees a snapshot of the database as it existed at the start of the transaction.

Deadlocks:
A deadlock is a situation in which two or more transactions are unable to proceed because each is waiting for the other to release a lock. In other words, transactions are blocked indefinitely, leading to a state where no progress can be made.

Conditions for Deadlock (4 Necessary Conditions):

1. Mutual Exclusion:
   - At least one resource must be held in a non-sharable mode, meaning only one transaction can use it at a time.

2. Hold and Wait:
   - A transaction holds a resource while waiting for another resource.

3. No Preemption:
   - Resources cannot be forcibly taken away from a transaction; they must be released voluntarily.

4. Circular Wait:
   - A set of transactions is involved in a cycle, where each is waiting for a resource held by the next.

Dealing with Deadlocks:

1. Deadlock Prevention:
   - Structuring transactions and resource allocation to ensure that at least one of the necessary conditions for deadlock cannot occur.
   - Example: Avoid circular wait by assigning a priority to resources and ensuring transactions request resources in a predefined order.

2. Deadlock Detection and Resolution:
   - Periodically check for deadlocks and, if detected, take corrective actions such as aborting one or more transactions to break the deadlock.
   - This approach allows deadlocks to occur but resolves them when detected.

3. Timeouts and Resource Preemption:
   - Assign a timeout to transactions; if a transaction cannot obtain all required locks within a specified time, it is aborted.
   - Resource preemption involves forcibly taking resources away from one transaction and allocating them to another to break the deadlock.

Concurrency control and deadlock management are crucial components in ensuring the effective and safe operation of multi-user database systems. Choosing an appropriate concurrency control mechanism and implementing deadlock prevention or resolution strategies help maintain database consistency and avoid scenarios where transactions are blocked indefinitely.


Question 7: Read about Database sharding and explain couple of real time examples where, why, how it this concept is used.

Answer =>
Database sharding is a horizontal database partitioning technique where a large database is divided into smaller, more manageable units called shards. Each shard is an independent database that stores a subset of the overall data. The goal of sharding is to distribute the data and workload across multiple servers, improving scalability, performance, and resource utilization.

Examples of Database Sharding:

1. E-commerce Platforms:
   - Why: E-commerce websites often handle a massive volume of data, including product information, customer details, and order history. As the user base and transaction volume increase, a single monolithic database may become a bottleneck.
   - How: Sharding can be employed to divide the product catalog, customer data, and order information into shards. Each shard is assigned to a separate server or cluster, allowing the e-commerce platform to scale horizontally and handle increased traffic efficiently. For example, customer data for customers with names starting from A to M could be stored in one shard, while N to Z could be in another.

2. Social Media Platforms:**
   - Why: Social media platforms accumulate vast amounts of user-generated content, including posts, comments, and media files. As the user base grows, the storage and retrieval of this data become challenging for a single database server.
   - How: Sharding enables social media platforms to distribute user data based on different criteria, such as geographical location, user IDs, or user attributes. For instance, user accounts from specific regions or with similar characteristics are grouped into shards. This distribution allows the platform to handle user interactions and content retrieval more efficiently.

3. Gaming Industry:
   - Why: Online multiplayer games generate a substantial amount of data related to user profiles, game state, and interactions. The number of simultaneous players can vary greatly, leading to varying workloads on the database.
   - How: Sharding helps in distributing game-related data across different shards, allowing each shard to handle a subset of players and game instances. For example, players from specific regions or those involved in similar gameplay styles may be grouped into separate shards. This ensures that the database load is distributed evenly, providing a better gaming experience and accommodating fluctuations in player activity.

4. Financial Services:
   - Why: Financial institutions deal with large volumes of transaction data, user accounts, and historical records. As the number of customers and transactions grows, managing a monolithic database becomes challenging.
   - How: Sharding can be applied to partition financial data based on criteria such as account numbers, transaction types, or geographic locations. Each shard manages a subset of the overall financial data, allowing the system to scale horizontally and handle increased transaction throughput. This helps in maintaining low-latency responses and ensures that data relevant to specific branches or regions is stored together.

In each of these real-time examples, database sharding is implemented to address scalability challenges and improve the performance and efficiency of data storage and retrieval. Sharding enables organizations to scale their databases horizontally, distribute workloads, and meet the growing demands of their applications and user bases.